{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"u1Qu22JjCczL"},"outputs":[],"source":["import pandas as pd\n","import pickle\n","import numpy as np\n","from xlrd import open_workbook\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from scipy.stats import uniform, randint\n","from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n","from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n","import warnings\n","from scipy.stats import uniform as sp_randFloat\n","from scipy.stats import randint as sp_randInt\n","from sklearn import ensemble\n","from sklearn import datasets\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.datasets import load_digits\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.ensemble import GradientBoostingRegressor\n","\n","\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","data=pd.read_excel('datasetterminal.xls','inputall')\n","\n","data= data.drop(columns= ['full_date'])\n","data = data[data['yeniyil'] != 1]\n","data = data[data['Weekday'] != 1]\n","\n","\n","\n","Y= data.miktar\n","X= data.drop(columns= ['miktar','ANT','DBR','DER','GUV','ISK','KIR','MAR','MER','NEM','SAM','TRA'])\n","sample = pd.read_excel('datasetterminal.xls','sample')\n","\n","sample = sample[sample['yeniyil'] != 1]\n","sample = sample[sample['Weekday'] != 1]\n","\n","\n","Ytarih= sample.full_date\n","Ytarih= pd.DataFrame(Ytarih)\n","print(Ytarih)\n","\n","sample= sample.drop(columns= ['full_date'])\n","\n","\n","'''\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n","\n","\n","# Define the grid of hyperparameters to search\n","\n","parameters = {'learning_rate': sp_randFloat(0.001,0.1),\n","              'subsample': sp_randFloat(),\n","              'n_estimators': sp_randInt(1000, 5000),\n","              'max_depth': sp_randInt(2, 8)\n","              }\n","\n","gradientboost = GradientBoostingRegressor()\n","\n","random_cv = RandomizedSearchCV(estimator=gradientboost,\n","                               param_distributions=parameters,\n","                               cv=5, n_iter=1500, n_jobs=-1)\n","\n","random_cv.fit(X_train,Y_train)\n","\n","print(random_cv.best_estimator_,1)\n","# Results from Random Search\n","print(\"\\n========================================================\")\n","print(\" Results from Random Search \")\n","print(\"========================================================\")\n","\n","print(\"\\n The best estimator across ALL searched params:\\n\",\n","      random_cv.best_estimator_)\n","\n","print(\"\\n The best score across ALL searched params:\\n\",\n","      random_cv.best_score_)\n","\n","print(\"\\n The best parameters across ALL searched params:\\n\",\n","      random_cv.best_params_)\n","print(\"\\n ========================================================\")\n","\n","\n","\n","\n","'''\n","\n","\n","model = ensemble.GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n","                          init=None, learning_rate=0.002,\n","                          loss='ls', max_depth=4, max_features=None,\n","                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n","                          min_impurity_split=None, min_samples_leaf=1,\n","                          min_samples_split=3, min_weight_fraction_leaf=0.0,\n","                          n_estimators= 7000, n_iter_no_change=None,\n","                          presort='deprecated', random_state=None,\n","                          subsample=0.6, tol=0.0001,\n","                          validation_fraction=0.1, verbose=0, warm_start=False)\n","\n","\n","model.fit(X , Y)\n","\n","#model = Prophet()\n","\n","NewPrediction = model.predict(sample)\n","NewPrediction = pd.DataFrame(NewPrediction)\n","NewPrediction.index = np.arange(1,len(NewPrediction)+1)\n","Ytarih.index = np.arange(1,len(Ytarih)+1)\n","\n","sonuclarim= pd.concat([Ytarih, NewPrediction], axis=1, sort=False)\n","sonuclarim.reset_index(drop=True, inplace=True)\n","\n","\n","writer = pd.ExcelWriter('sonuclargradientall.xls')\n","sonuclarim.to_excel(writer, \"pythonbas\" )\n","writer.save()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNW1sODvl+9GcN/K25QCu5g","name":"Untitled0.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
